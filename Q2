set.seed(344) 


n <- 1000

# Simulating predictor variables
age_group <- sample(c("18-29", "30-44", "45+"), n, replace = TRUE, prob = c(0.3, 0.4, 0.3))
income_group <- sample(c("Low", "Medium", "High"), n, replace = TRUE, prob = c(0.3, 0.5, 0.2))
education_level <- sample(c("High School", "Bachelor's", "Master's", "Doctorate"), n, replace = TRUE, prob = c(0.25, 0.25, 0.25, 0.25))

# Encoding predictors numerically for logistic regression
age_numeric <- ifelse(age_group == "18-29", 1, ifelse(age_group == "30-44", 2, 3))
income_numeric <- ifelse(income_group == "Low", 1, ifelse(income_group == "Medium", 2, 3))
education_numeric <- ifelse(education_level == "High School", 1, ifelse(education_level == "Bachelor's", 2, ifelse(education_level == "Master's", 3, 4)))

# Simulating the binary outcome based on predictors
# Logistic function to simulate probability of 'Yes' based on predictors
logit_prob <- function(age, income, education) {
  intercept + age * 0.2 + income * 0.15 + education * (-0.1)
}
intercept <- -1 # Base log odds of supporting without considering predictors
probs <- plogis(logit_prob(age_numeric, income_numeric, education_numeric))

# Generating binary outcome
support <- rbinom(n, 1, prob = probs)

# Create data frame
data <- data.frame(support, age_group, income_group, education_level)


model <- glm(support ~ age_group + income_group + education_level, family = binomial(link = "logit"), data = data)

# Summary of the model to inspect associations
summary(model)
